{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "## Implementation of TF-IDF"}, {"metadata": {}, "cell_type": "markdown", "source": "Motivation: Spark MLlib tools are intended to generate feature vectors for ML algorithms. \nThrough that implementation, it's not possible to figure out the weight for a particular term in a particular document."}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "import numpy as np\nimport pyspark.sql.functions as f\nfrom pyspark.sql.types import StructField, StructType, StringType, ArrayType, IntegerType, FloatType", "execution_count": 187, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "sentences = [\"one green one white and one pink\", \"no green is blue\", \"no dark blue no light blue and no pink\"]", "execution_count": 162, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "data = enumerate(s.split() for s in sentences)", "execution_count": 163, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "schema = StructType([\n    StructField(\"doc_id\", IntegerType(), True),\n    StructField(\"document\", ArrayType(StringType()), True)\n])", "execution_count": 164, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "df = spark.createDataFrame(data, schema)", "execution_count": 165, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "df.show(5, False)", "execution_count": 166, "outputs": [{"output_type": "stream", "text": "+------+------------------------------------------------+\n|doc_id|document                                        |\n+------+------------------------------------------------+\n|0     |[one, green, one, white, and, one, pink]        |\n|1     |[no, green, is, blue]                           |\n|2     |[no, dark, blue, no, light, blue, and, no, pink]|\n+------+------------------------------------------------+", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "### Calculate Term Frequency"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "unfolded_df = df.withColumn('token', f.explode(f.col('document')))", "execution_count": 167, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "unfolded_df.show(20, False)", "execution_count": 168, "outputs": [{"output_type": "stream", "text": "+------+------------------------------------------------+-----+\n|doc_id|document                                        |token|\n+------+------------------------------------------------+-----+\n|0     |[one, green, one, white, and, one, pink]        |one  |\n|0     |[one, green, one, white, and, one, pink]        |green|\n|0     |[one, green, one, white, and, one, pink]        |one  |\n|0     |[one, green, one, white, and, one, pink]        |white|\n|0     |[one, green, one, white, and, one, pink]        |and  |\n|0     |[one, green, one, white, and, one, pink]        |one  |\n|0     |[one, green, one, white, and, one, pink]        |pink |\n|1     |[no, green, is, blue]                           |no   |\n|1     |[no, green, is, blue]                           |green|\n|1     |[no, green, is, blue]                           |is   |\n|1     |[no, green, is, blue]                           |blue |\n|2     |[no, dark, blue, no, light, blue, and, no, pink]|no   |\n|2     |[no, dark, blue, no, light, blue, and, no, pink]|dark |\n|2     |[no, dark, blue, no, light, blue, and, no, pink]|blue |\n|2     |[no, dark, blue, no, light, blue, and, no, pink]|no   |\n|2     |[no, dark, blue, no, light, blue, and, no, pink]|light|\n|2     |[no, dark, blue, no, light, blue, and, no, pink]|blue |\n|2     |[no, dark, blue, no, light, blue, and, no, pink]|and  |\n|2     |[no, dark, blue, no, light, blue, and, no, pink]|no   |\n|2     |[no, dark, blue, no, light, blue, and, no, pink]|pink |\n+------+------------------------------------------------+-----+", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# Count the frequency of each token in each document\ndf_TF = unfolded_df.groupBy(\"doc_id\", \"token\").agg(f.count(\"document\").alias(\"tf\"))", "execution_count": 194, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "df_TF.show(20, False)", "execution_count": 170, "outputs": [{"output_type": "stream", "text": "+------+-----+---+\n|doc_id|token|tf |\n+------+-----+---+\n|0     |and  |1  |\n|0     |green|1  |\n|1     |no   |1  |\n|2     |light|1  |\n|2     |no   |3  |\n|1     |is   |1  |\n|0     |pink |1  |\n|2     |and  |1  |\n|1     |blue |1  |\n|2     |pink |1  |\n|2     |dark |1  |\n|0     |white|1  |\n|2     |blue |2  |\n|1     |green|1  |\n|0     |one  |3  |\n+------+-----+---+", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "### Calculate Inverse Document Frequency"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# Calculate the Document Frequnecy. i.e. is the number of documents having a given term\ndf_DF = unfolded_df.groupBy(\"token\").agg(f.countDistinct(\"doc_id\").alias(\"df\"))", "execution_count": 172, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "df_DF.show(20, False)", "execution_count": 173, "outputs": [{"output_type": "stream", "text": "+-----+---+\n|token|df |\n+-----+---+\n|green|2  |\n|one  |1  |\n|light|1  |\n|white|1  |\n|is   |1  |\n|pink |2  |\n|dark |1  |\n|and  |2  |\n|no   |2  |\n|blue |2  |\n+-----+---+", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "num_docs = df.count() * 1.", "execution_count": 176, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# Apply the IDF formula\ndf_IDF = df_DF.withColumn(\"idf\", f.log((num_docs + 1)/(f.col(\"df\") + 1)))", "execution_count": 192, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "df_IDF.show(20, False)", "execution_count": 193, "outputs": [{"output_type": "stream", "text": "+-----+---+-------------------+\n|token|df |idf                |\n+-----+---+-------------------+\n|green|2  |0.28768207245178085|\n|one  |1  |0.6931471805599453 |\n|light|1  |0.6931471805599453 |\n|white|1  |0.6931471805599453 |\n|is   |1  |0.6931471805599453 |\n|pink |2  |0.28768207245178085|\n|dark |1  |0.6931471805599453 |\n|and  |2  |0.28768207245178085|\n|no   |2  |0.28768207245178085|\n|blue |2  |0.28768207245178085|\n+-----+---+-------------------+", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "### Extract TF-IDF"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "df_TF_IDF = df_TF.join(df_IDF, \"token\", \"left\").withColumn(\"tf_idf\", f.col(\"tf\") * f.col(\"idf\"))", "execution_count": 196, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "df_TF_IDF.printSchema()", "execution_count": 197, "outputs": [{"output_type": "stream", "text": "root\n |-- token: string (nullable = true)\n |-- doc_id: integer (nullable = true)\n |-- tf: long (nullable = false)\n |-- df: long (nullable = true)\n |-- idf: double (nullable = true)\n |-- tf_idf: double (nullable = true)", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "df_TF_IDF.show(20, False)", "execution_count": 198, "outputs": [{"output_type": "stream", "text": "+-----+------+---+---+-------------------+-------------------+\n|token|doc_id|tf |df |idf                |tf_idf             |\n+-----+------+---+---+-------------------+-------------------+\n|green|0     |1  |2  |0.28768207245178085|0.28768207245178085|\n|green|1     |1  |2  |0.28768207245178085|0.28768207245178085|\n|one  |0     |3  |1  |0.6931471805599453 |2.0794415416798357 |\n|light|2     |1  |1  |0.6931471805599453 |0.6931471805599453 |\n|white|0     |1  |1  |0.6931471805599453 |0.6931471805599453 |\n|is   |1     |1  |1  |0.6931471805599453 |0.6931471805599453 |\n|pink |0     |1  |2  |0.28768207245178085|0.28768207245178085|\n|pink |2     |1  |2  |0.28768207245178085|0.28768207245178085|\n|dark |2     |1  |1  |0.6931471805599453 |0.6931471805599453 |\n|and  |0     |1  |2  |0.28768207245178085|0.28768207245178085|\n|and  |2     |1  |2  |0.28768207245178085|0.28768207245178085|\n|no   |1     |1  |2  |0.28768207245178085|0.28768207245178085|\n|no   |2     |3  |2  |0.28768207245178085|0.8630462173553426 |\n|blue |1     |1  |2  |0.28768207245178085|0.28768207245178085|\n|blue |2     |2  |2  |0.28768207245178085|0.5753641449035617 |\n+-----+------+---+---+-------------------+-------------------+", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Summarized code"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "def calc_tf_idf(df, id_col=\"doc_id\", tokens_col=\"document\"):\n\n    # Calculate number of documents\n    num_docs = df.count() * 1.\n\n    # Turn array of tokens into rows of tokens\n    unfolded_df = df.withColumn(\"token\", f.explode(f.col(tokens_col)))\n\n    # Calculate Term Frequency\n    df_TF = unfolded_df.groupBy(id_col, \"token\").agg(f.count(tokens_col).alias(\"tf\"))\n\n    # Calculate Inverse Document Frequency\n    df_IDF = unfolded_df\\\n        .groupBy(\"token\").agg(f.countDistinct(id_col).alias(\"df\"))\\\n        .withColumn(\"idf\", f.log((num_docs + 1)/(f.col(\"df\") + 1)))\n\n    # Calculate TF.IDF\n    TF_IDF = df_TF\\\n        .join(df_IDF, \"token\", \"left\")\\\n        .withColumn(\"tf_idf\", f.col(\"tf\") * f.col(\"idf\"))\n    \n    return TF_IDF.select(id_col, \"token\", \"tf_idf\")", "execution_count": 203, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "test = calc_tf_idf(df, id_col=\"doc_id\", tokens_col=\"document\")", "execution_count": 204, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "test.show(20, False)", "execution_count": 205, "outputs": [{"output_type": "stream", "text": "+------+-----+-------------------+\n|doc_id|token|tf_idf             |\n+------+-----+-------------------+\n|0     |green|0.28768207245178085|\n|1     |green|0.28768207245178085|\n|0     |one  |2.0794415416798357 |\n|2     |light|0.6931471805599453 |\n|0     |white|0.6931471805599453 |\n|1     |is   |0.6931471805599453 |\n|0     |pink |0.28768207245178085|\n|2     |pink |0.28768207245178085|\n|2     |dark |0.6931471805599453 |\n|0     |and  |0.28768207245178085|\n|2     |and  |0.28768207245178085|\n|1     |no   |0.28768207245178085|\n|2     |no   |0.8630462173553426 |\n|1     |blue |0.28768207245178085|\n|2     |blue |0.5753641449035617 |\n+------+-----+-------------------+", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "pyspark3kernel", "display_name": "PySpark3", "language": ""}, "language_info": {"name": "pyspark3", "mimetype": "text/x-python", "codemirror_mode": {"name": "python", "version": 3}, "pygments_lexer": "python3"}}, "nbformat": 4, "nbformat_minor": 2}